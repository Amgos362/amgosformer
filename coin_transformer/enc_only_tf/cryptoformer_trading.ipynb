{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amgos45/coin_transformer/amgos/lib/python3.8/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/tmp/ipykernel_824211/331309710.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"model_experiment_15.pth\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 5분봉 (2024-12-18 16:30:00) 예측 결과:\n",
      "  - 상승/하락 예측: 하락\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 전처리 함수: rolling minmax scaling (window=24)\n",
    "def rolling_minmax_scale(series, window=24):\n",
    "    roll_min = series.rolling(window=window, min_periods=window).min()\n",
    "    roll_max = series.rolling(window=window, min_periods=window).max()\n",
    "    scaled = (series - roll_min) / ((roll_max - roll_min) + 1e-8)\n",
    "    scaled = scaled.replace([np.inf, -np.inf], np.nan)\n",
    "    scaled = scaled.fillna(1.0)\n",
    "    return scaled.clip(upper=1.0)\n",
    "\n",
    "# 전처리 함수: binning 및 one-hot 인코딩 (OHLC 열, bins=100)\n",
    "def bin_and_encode(data, features, bins=100, drop_original=True):\n",
    "    for feature in features:\n",
    "        data[f'{feature}_Bin'] = pd.cut(data[feature], bins=bins, labels=False)\n",
    "        one_hot = pd.get_dummies(data[f'{feature}_Bin'], prefix=f'{feature}_Bin').astype(np.int32)\n",
    "        expected_columns = [f'{feature}_Bin_{i}' for i in range(bins)]\n",
    "        one_hot = one_hot.reindex(columns=expected_columns, fill_value=0)\n",
    "        data = pd.concat([data, one_hot], axis=1)\n",
    "        if drop_original:\n",
    "            data.drop(columns=[f'{feature}_Bin'], inplace=True)\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numeric_cols:\n",
    "        data[col] = data[col].astype(np.float32)\n",
    "    return data\n",
    "\n",
    "# 분류 모델 (상승/하락 예측) 정의: regression 헤드 제거\n",
    "class EncoderOnlyTransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=512, num_layers=6, nhead=8, \n",
    "                 ffn_dim=2048, num_classes=2, max_seq_len=24):\n",
    "        super(EncoderOnlyTransformerClassifier, self).__init__()\n",
    "        self.token_embedding = nn.Linear(input_dim, embedding_dim)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, embedding_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim, nhead=nhead, dim_feedforward=ffn_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        x = self.token_embedding(x)\n",
    "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
    "        pos_emb = self.position_embedding(positions)\n",
    "        x = x + pos_emb\n",
    "        x = x.transpose(0, 1)  # [seq_len, batch, features]\n",
    "        x = self.transformer_encoder(x)\n",
    "        return self.fc(x[-1, :, :])  # 마지막 타임스탭의 출력 사용\n",
    "\n",
    "# device 및 입력 차원 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = 400  # OHLC 4개 feature를 100 구간으로 binning했으므로\n",
    "\n",
    "# 분류 모델 생성 후, model_experiment_15.pth의 가중치를 로드\n",
    "model = EncoderOnlyTransformerClassifier(input_dim=input_dim).to(device)\n",
    "state_dict = torch.load(\"model_experiment_15.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "# CSV 파일에서 시계열 데이터 불러오기 (시간 인덱스가 있다고 가정)\n",
    "data = pd.read_csv(\"ETH_upbit_KRW_min5.csv\", index_col=0, parse_dates=True)\n",
    "data = data.sort_index()\n",
    "\n",
    "# 마지막 시점이 2024-12-18 16:25:00인 부분까지의 데이터에서 마지막 24봉을 입력 시퀀스로 사용\n",
    "target_last_time = pd.Timestamp(\"2024-12-18 16:25:00\")\n",
    "if target_last_time not in data.index:\n",
    "    print(\"지정한 마지막 시간이 데이터에 없습니다. 데이터의 마지막 행을 사용합니다.\")\n",
    "    target_last_time = data.index[-1]\n",
    "input_data = data.loc[:target_last_time].tail(24).copy()\n",
    "\n",
    "# OHLC 열에 대해 전처리 적용\n",
    "ohlc_features = ['open', 'high', 'low', 'close']\n",
    "for feature in ohlc_features:\n",
    "    input_data[feature] = rolling_minmax_scale(input_data[feature], window=24)\n",
    "input_data_binned = bin_and_encode(input_data.copy(), ohlc_features, bins=100, drop_original=True)\n",
    "final_input_columns = [col for col in input_data_binned.columns if '_Bin_' in col]\n",
    "input_seq = input_data_binned[final_input_columns].values  # (24, 400)\n",
    "\n",
    "# 모델 입력 형태로 변환 (배치 차원 추가)\n",
    "x = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "# 예측 수행: 상승/하락 분류 예측\n",
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "    class_pred = torch.argmax(output, dim=1).item()  # 1: 상승, 0: 하락\n",
    "\n",
    "trend = \"상승\" if class_pred == 1 else \"하락\"\n",
    "next_candle_time = pd.Timestamp(\"2024-12-18 16:30:00\")\n",
    "print(f\"다음 5분봉 ({next_candle_time}) 예측 결과:\")\n",
    "print(f\"  - 상승/하락 예측: {trend}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amgos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
